{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOQj5oTfHXopzWw7xiUS/8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/39minutes/IDS-2025/blob/main/IDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRMrx_JOc0zt",
        "outputId": "f3227d88-85ad-4cb2-c5c2-3a5f07510fe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Окружение готово!\n",
            "\n",
            "Скачиваем NSL-KDD...\n",
            "data/train.csv      100%[===================>]  13.94M  --.-KB/s    in 0.1s    \n",
            "data/test.csv       100%[===================>]   2.52M  --.-KB/s    in 0.06s   \n",
            "Данные скачаны!\n",
            "\n",
            "Загружаем и обрабатываем датасет...\n",
            "Предобработка завершена: 148,516 записей, 40 классов атак\n",
            "\n",
            "Устройство: cpu\n",
            "\n",
            "Обучение LSTM-классификатора...\n",
            "   Эпоха 4/12 завершена\n",
            "   Эпоха 8/12 завершена\n",
            "   Эпоха 12/12 завершена\n",
            "\n",
            "══════════════════════════════════════════════════════════════════════\n",
            "     РЕЗУЛЬТАТЫ LSTM-КЛАССИФИКАТОРА\n",
            "══════════════════════════════════════════════════════════════════════\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        apache2     0.8022    0.9932    0.8875       147\n",
            "           back     0.8344    0.9962    0.9081       263\n",
            "buffer_overflow     0.0550    0.6000    0.1008        10\n",
            "      ftp_write     0.0267    1.0000    0.0519         2\n",
            "   guess_passwd     0.3587    0.8794    0.5096       257\n",
            "     httptunnel     0.4561    0.9630    0.6190        27\n",
            "           imap     0.1818    1.0000    0.3077         2\n",
            "        ipsweep     0.9134    0.9866    0.9486       748\n",
            "           land     0.6250    1.0000    0.7692         5\n",
            "     loadmodule     0.0286    0.5000    0.0541         2\n",
            "       mailbomb     0.4917    1.0000    0.6592        59\n",
            "          mscan     0.5902    0.9698    0.7338       199\n",
            "       multihop     0.0143    0.4000    0.0276         5\n",
            "          named     0.0204    0.3333    0.0385         3\n",
            "        neptune     0.9986    0.9893    0.9939      9175\n",
            "           nmap     0.8575    0.9617    0.9066       313\n",
            "         normal     0.9993    0.7894    0.8820     15411\n",
            "           perl     0.0000    0.0000    0.0000         1\n",
            "            phf     0.3333    1.0000    0.5000         1\n",
            "            pod     0.8136    1.0000    0.8972        48\n",
            "      portsweep     0.9521    0.9644    0.9582       618\n",
            "   processtable     0.8562    1.0000    0.9226       137\n",
            "             ps     0.1538    0.6667    0.2500         3\n",
            "        rootkit     0.0042    0.4000    0.0084         5\n",
            "          saint     0.0990    0.7969    0.1762        64\n",
            "          satan     0.6865    0.4760    0.5622       874\n",
            "       sendmail     0.0306    1.0000    0.0594         3\n",
            "          smurf     0.8768    1.0000    0.9344       662\n",
            "  snmpgetattack     0.0772    0.5278    0.1348        36\n",
            "      snmpguess     0.5289    0.9697    0.6845        66\n",
            "            spy     0.0000    0.0000    0.0000         0\n",
            "      sqlattack     0.0000    0.0000    0.0000         0\n",
            "       teardrop     0.9526    1.0000    0.9757       181\n",
            "       udpstorm     0.0000    0.0000    0.0000         0\n",
            "    warezclient     0.2323    0.9607    0.3742       178\n",
            "    warezmaster     0.4759    0.8705    0.6154       193\n",
            "           worm     0.0000    0.0000    0.0000         0\n",
            "          xlock     0.1250    0.5000    0.2000         2\n",
            "         xsnoop     0.0588    1.0000    0.1111         1\n",
            "          xterm     0.2727    1.0000    0.4286         3\n",
            "\n",
            "       accuracy                         0.8665     29704\n",
            "      macro avg     0.3946    0.7374    0.4548     29704\n",
            "   weighted avg     0.9555    0.8665    0.8992     29704\n",
            "\n",
            "\n",
            "Обучение автоэнкодера (только нормальный трафик)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Эпоха 20/60 → MSE: 0.0014878\n",
            "   Эпоха 40/60 → MSE: 0.0012204\n",
            "   Эпоха 60/60 → MSE: 0.0008374\n",
            "\n",
            "════════════════════════════════════════════════════════════════════════════════\n",
            "                     ИТОГОВЫЕ РЕЗУЛЬТАТЫ ГИБРИДНОЙ IDS\n",
            "════════════════════════════════════════════════════════════════════════════════\n",
            "Общая точность LSTM-классификатора:           86.648%\n",
            "Порог ошибки реконструкции (автоэнкодер):     0.013465\n",
            "Средняя MSE на нормальном трафике:            0.000953\n",
            "Количество классов атак в датасете:           40\n",
            "Всего записей в датасете:                     148,516\n",
            "Нормальный трафик:                            77,053 записей\n",
            "Атак в датасете:                              71,463 записей\n",
            "\n",
            "════════════════════════════════════════════════════════════════════════════════\n",
            "           ПРИМЕРЫ РАБОТЫ ГИБРИДНОЙ МОДЕЛИ В РЕАЛЬНОМ ВРЕМЕНИ\n",
            "════════════════════════════════════════════════════════════════════════════════\n",
            "     0. → Предсказано: rootkit         | Аномалия: нормально | MSE=0.00015 → Правда: normal\n",
            "  5000. → Предсказано: neptune         | Аномалия: АНОМАЛИЯ  | MSE=0.03006 → Правда: neptune\n",
            " 15000. → Предсказано: neptune         | Аномалия: АНОМАЛИЯ  | MSE=0.03335 → Правда: neptune\n",
            " 30000. → Предсказано: normal          | Аномалия: нормально | MSE=0.00003 → Правда: normal\n",
            " 77777. → Предсказано: neptune         | Аномалия: АНОМАЛИЯ  | MSE=0.03439 → Правда: neptune\n",
            "120000. → Предсказано: normal          | Аномалия: нормально | MSE=0.00001 → Правда: normal\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# КУРСОВАЯ РАБОТА: ГИБРИДНАЯ IDS НА ОСНОВЕ LSTM + AUTOENCODER (NSL-KDD)\n",
        "# =============================================================================\n",
        "\n",
        "# ЯЧЕЙКА 1 — Подготовка окружения\n",
        "!mkdir -p data models\n",
        "!pip install -q scapy imbalanced-learn joblib 2>/dev/null\n",
        "print(\"Окружение готово!\\n\")\n",
        "\n",
        "# ЯЧЕЙКА 2 — Скачивание NSL-KDD\n",
        "print(\"Скачиваем NSL-KDD...\")\n",
        "!wget -q --show-progress -O data/train.csv https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTrain+.csv\n",
        "!wget -q --show-progress -O data/test.csv https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTest+.csv\n",
        "print(\"Данные скачаны!\\n\")\n",
        "\n",
        "# ЯЧЕЙКА 3 — Предобработка\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "\n",
        "print(\"Загружаем и обрабатываем датасет...\")\n",
        "train = pd.read_csv('data/train.csv', header=None)\n",
        "test  = pd.read_csv('data/test.csv', header=None)\n",
        "df = pd.concat([train, test], ignore_index=True)\n",
        "\n",
        "columns = ['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent','hot',\n",
        "           'num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root','num_file_creations',\n",
        "           'num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','srv_count',\n",
        "           'serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate',\n",
        "           'srv_diff_host_rate','dst_host_count','dst_host_srv_count','dst_host_same_srv_rate',\n",
        "           'dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate',\n",
        "           'dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate',\n",
        "           'dst_host_srv_rerror_rate','label','difficulty']\n",
        "\n",
        "df.columns = columns\n",
        "df = df.drop('difficulty', axis=1)\n",
        "\n",
        "# Кодирование категориальных признаков\n",
        "df['protocol_type'] = LabelEncoder().fit_transform(df['protocol_type'])\n",
        "df['service']       = LabelEncoder().fit_transform(df['service'])\n",
        "df['flag']          = LabelEncoder().fit_transform(df['flag'])\n",
        "\n",
        "le_label = LabelEncoder()\n",
        "y_all = le_label.fit_transform(df['label'])\n",
        "X_raw = df.drop('label', axis=1).values.astype(np.float32)\n",
        "\n",
        "scaler_lstm = StandardScaler()\n",
        "X_lstm = scaler_lstm.fit_transform(X_raw)\n",
        "\n",
        "scaler_ae = MinMaxScaler()\n",
        "X_ae = scaler_ae.fit_transform(X_raw)\n",
        "\n",
        "X_train_lstm, X_test_lstm, y_train, y_test = train_test_split(\n",
        "    X_lstm, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
        ")\n",
        "\n",
        "X_train_lstm = X_train_lstm.reshape(-1, 1, X_train_lstm.shape[1])\n",
        "X_test_lstm  = X_test_lstm.reshape(-1, 1, X_test_lstm.shape[1])\n",
        "\n",
        "joblib.dump(scaler_lstm, 'models/scaler_lstm.pkl')\n",
        "joblib.dump(scaler_ae,   'models/scaler_ae.pkl')\n",
        "joblib.dump(le_label,    'models/label_encoder.pkl')\n",
        "\n",
        "print(f\"Предобработка завершена: {len(df):,} записей, {len(le_label.classes_)} классов атак\\n\")\n",
        "\n",
        "# ЯЧЕЙКА 4 — Обучение моделей\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Устройство: {device}\\n\")\n",
        "\n",
        "# === LSTM ===\n",
        "print(\"Обучение LSTM-классификатора...\")\n",
        "class_weights = torch.tensor(compute_class_weight('balanced', classes=np.unique(y_train), y=y_train),\n",
        "                             dtype=torch.float32).to(device)\n",
        "\n",
        "class LSTM_IDS(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, 128, num_layers=2, batch_first=True, dropout=0.4)\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "model_lstm = LSTM_IDS(X_train_lstm.shape[2], len(le_label.classes_)).to(device)\n",
        "loader = DataLoader(TensorDataset(torch.tensor(X_train_lstm), torch.tensor(y_train, dtype=torch.long)),\n",
        "                    batch_size=256, shuffle=True)\n",
        "\n",
        "optimizer = torch.optim.Adam(model_lstm.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "for epoch in range(12):\n",
        "    model_lstm.train()\n",
        "    for x_b, y_b in loader:\n",
        "        x_b, y_b = x_b.to(device), y_b.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model_lstm(x_b), y_b)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if (epoch + 1) % 4 == 0:\n",
        "        print(f\"   Эпоха {epoch+1}/12 завершена\")\n",
        "\n",
        "model_lstm.eval()\n",
        "with torch.no_grad():\n",
        "    preds = torch.argmax(model_lstm(torch.tensor(X_test_lstm, dtype=torch.float32).to(device)), dim=1).cpu().numpy()\n",
        "\n",
        "lstm_accuracy = accuracy_score(y_test, preds)\n",
        "present_classes = np.unique(np.concatenate([y_train, y_test]))\n",
        "present_names = le_label.classes_[present_classes]\n",
        "\n",
        "print(\"\\n\" + \"═\" * 70)\n",
        "print(\"     РЕЗУЛЬТАТЫ LSTM-КЛАССИФИКАТОРА\")\n",
        "print(\"═\" * 70)\n",
        "print(classification_report(y_test, preds, labels=present_classes, target_names=present_names, digits=4))\n",
        "\n",
        "# === Autoencoder ===\n",
        "print(\"\\nОбучение автоэнкодера (только нормальный трафик)...\")\n",
        "normal_mask = df['label'] == 'normal'\n",
        "normal_tensor = torch.tensor(X_ae[normal_mask].values if isinstance(X_ae, pd.DataFrame) else X_ae[normal_mask],\n",
        "                             dtype=torch.float32).to(device)\n",
        "ae_loader = DataLoader(normal_tensor, batch_size=256, shuffle=True)\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(dim, 256), nn.ReLU(),\n",
        "            nn.Linear(256, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 32), nn.ReLU(),\n",
        "            nn.Linear(32, 16), nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(16, 32), nn.ReLU(),\n",
        "            nn.Linear(32, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 256), nn.ReLU(),\n",
        "            nn.Linear(256, dim), nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x): return self.decoder(self.encoder(x))\n",
        "\n",
        "ae = Autoencoder(X_ae.shape[1]).to(device)\n",
        "opt_ae = torch.optim.Adam(ae.parameters(), lr=0.0005)\n",
        "\n",
        "for epoch in range(60):\n",
        "    for batch in ae_loader:\n",
        "        opt_ae.zero_grad()\n",
        "        recon = ae(batch)\n",
        "        loss = nn.MSELoss()(recon, batch)\n",
        "        loss.backward()\n",
        "        opt_ae.step()\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print(f\"   Эпоха {epoch+1:2d}/60 → MSE: {loss.item():.7f}\")\n",
        "\n",
        "ae.eval()\n",
        "with torch.no_grad():\n",
        "    recon_normal = ae(normal_tensor)\n",
        "    mse_normal = torch.mean((recon_normal - normal_tensor)**2, dim=1)\n",
        "    threshold = (mse_normal.mean() + 3 * mse_normal.std()).item()\n",
        "\n",
        "torch.save(model_lstm.state_dict(), 'models/lstm_final.pth')\n",
        "torch.save(ae.state_dict(), 'models/autoencoder_final.pth')\n",
        "joblib.dump(threshold, 'models/threshold.pkl')\n",
        "\n",
        "# ЯЧЕЙКА 5 — Гибридное предсказание\n",
        "threshold = joblib.load('models/threshold.pkl')\n",
        "\n",
        "def predict_hybrid(vector):\n",
        "    vec = vector.reshape(1, -1)\n",
        "    x_l = torch.tensor(scaler_lstm.transform(vec).reshape(1,1,-1), dtype=torch.float32).to(device)\n",
        "    x_a = torch.tensor(scaler_ae.transform(vec), dtype=torch.float32).to(device)\n",
        "\n",
        "    model_lstm.eval(); ae.eval()\n",
        "    with torch.no_grad():\n",
        "        attack_id = torch.argmax(model_lstm(x_l)).item()\n",
        "        attack_name = le_label.inverse_transform([attack_id])[0]\n",
        "        mse = torch.mean((ae(x_a) - x_a)**2).item()\n",
        "        anomaly = \"АНОМАЛИЯ\" if mse > threshold else \"нормально\"\n",
        "    return attack_name, mse, anomaly\n",
        "\n",
        "# ЯЧЕЙКА 6 — ФИНАЛЬНЫЕ РЕЗУЛЬТАТЫ И КРАСИВЫЙ ВЫВОД\n",
        "print(\"\\n\" + \"═\" * 80)\n",
        "print(\"                     ИТОГОВЫЕ РЕЗУЛЬТАТЫ ГИБРИДНОЙ IDS\")\n",
        "print(\"═\" * 80)\n",
        "print(f\"{'Общая точность LSTM-классификатора:':<45} {lstm_accuracy*100:6.3f}%\")\n",
        "print(f\"{'Порог ошибки реконструкции (автоэнкодер):':<45} {threshold:.6f}\")\n",
        "print(f\"{'Средняя MSE на нормальном трафике:':<45} {mse_normal.mean().item():.6f}\")\n",
        "print(f\"{'Количество классов атак в датасете:':<45} {len(le_label.classes_)}\")\n",
        "print(f\"{'Всего записей в датасете:':<45} {len(df):,}\")\n",
        "print(f\"{'Нормальный трафик:':<45} {sum(df['label'] == 'normal'):,} записей\")\n",
        "print(f\"{'Атак в датасете:':<45} {len(df) - sum(df['label'] == 'normal'):,} записей\")\n",
        "\n",
        "print(\"\\n\" + \"═\" * 80)\n",
        "print(\"           ПРИМЕРЫ РАБОТЫ ГИБРИДНОЙ МОДЕЛИ В РЕАЛЬНОМ ВРЕМЕНИ\")\n",
        "print(\"═\" * 80)\n",
        "test_indices = [0, 5000, 15000, 30000, 77777, 120000]\n",
        "for idx in test_indices:\n",
        "    if idx < len(df):\n",
        "        sample = df.drop('label', axis=1).iloc[idx].values\n",
        "        true = df['label'].iloc[idx]\n",
        "        pred_attack, mse_val, anomaly_status = predict_hybrid(sample)\n",
        "        print(f\"{idx:6d}. → Предсказано: {pred_attack:15} | Аномалия: {anomaly_status:9} | MSE={mse_val:.5f} → Правда: {true}\")\n",
        "\n",
        "S\n"
      ]
    }
  ]
}